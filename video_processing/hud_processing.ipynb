{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video HUD Processing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline for processing lab video analysis results into a HUD overlay video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import our processing modules\n",
    "from video_processing.event_merger import merge_events_to_timeline\n",
    "from video_processing.json_to_models import load_procedure_from_json, load_objective_events_from_json, load_analysis_events_from_json\n",
    "from video_processing.video_hud_overlay import create_hud_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and examine the original JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original analysis files\n",
    "base_dir = Path.cwd().parent\n",
    "\n",
    "# Load analysis events\n",
    "with open(base_dir / \"analysis_events_result.json\", 'r') as f:\n",
    "    analysis_data = json.load(f)\n",
    "    \n",
    "print(f\"Analysis events: {len(analysis_data['events'])} events\")\n",
    "for i, event in enumerate(analysis_data['events'][:3]):  # Show first 3\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Type: {'Warning' if 'warning_message' in event else 'Well State'}\")\n",
    "    print(f\"  Time: {event['timestamp_range']}\")\n",
    "    if 'warning_message' in event:\n",
    "        print(f\"  Warning: {event['warning_message']}\")\n",
    "    elif 'well_id' in event:\n",
    "        print(f\"  Well: {event['well_id']} - {'Complete' if event['is_complete'] else 'Partial'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load objective events\n",
    "with open(base_dir / \"objective_events_result.json\", 'r') as f:\n",
    "    objective_data = json.load(f)\n",
    "    \n",
    "print(f\"Objective events: {len(objective_data['events'])} events\")\n",
    "for i, event in enumerate(objective_data['events'][:5]):  # Show first 5\n",
    "    print(f\"\\nEvent {i+1}:\")\n",
    "    print(f\"  Time: {event['timestamp_range']}\")\n",
    "    if 'new_setting_ul' in event:\n",
    "        print(f\"  Type: Pipette Setting - {event['new_setting_ul']}μL\")\n",
    "    elif 'reagent' in event:\n",
    "        thinking = event['thinking'].lower()\n",
    "        event_type = \"Aspiration\" if \"aspirate\" in thinking else \"Dispensing\"\n",
    "        print(f\"  Type: {event_type} - {event['reagent']['name']} ({event['reagent']['volume_ul']}μL)\")\n",
    "    else:\n",
    "        print(f\"  Type: Tip Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load procedure\n",
    "with open(base_dir / \"procedure_result.json\", 'r') as f:\n",
    "    procedure_data = json.load(f)\n",
    "    \n",
    "print(f\"Procedure goal wells: {len(procedure_data['goal_wells'])}\")\n",
    "for well in procedure_data['goal_wells']:\n",
    "    reagents = [f\"{r['name']} ({r['volume_ul']}μL)\" for r in well['reagents']]\n",
    "    print(f\"  {well['well_id']}: {', '.join(reagents)}\")\n",
    "    \n",
    "print(f\"\\nReagent sources: {', '.join(procedure_data['reagent_sources'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process events into timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the event merger\n",
    "print(\"Merging events into timeline...\")\n",
    "merge_events_to_timeline(\n",
    "    str(base_dir / \"analysis_events_result.json\"),\n",
    "    str(base_dir / \"objective_events_result.json\"),\n",
    "    str(base_dir / \"procedure_result.json\"),\n",
    "    str(base_dir / \"video_processing\" / \"merged_timeline.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the merged timeline\n",
    "with open(base_dir / \"video_processing\" / \"merged_timeline.json\", 'r') as f:\n",
    "    timeline_data = json.load(f)\n",
    "\n",
    "print(f\"Total events in timeline: {timeline_data['total_events']}\")\n",
    "print(\"\\nFirst 10 events:\")\n",
    "for i, event in enumerate(timeline_data['timeline'][:10]):\n",
    "    print(f\"  {i+1:2d}. {event['start_time']:.1f}s - {event['end_time']:.1f}s: {event['title']} [{event['event_type']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create HUD overlay video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if input video exists\n",
    "input_video = base_dir / \"videos\" / \"output_long_again_2_timestamped.mp4\"\n",
    "output_video = base_dir / \"video_processing\" / \"hud_overlay_video.mp4\"\n",
    "\n",
    "print(f\"Input video exists: {input_video.exists()}\")\n",
    "print(f\"Input video path: {input_video}\")\n",
    "print(f\"Output video path: {output_video}\")\n",
    "\n",
    "if input_video.exists():\n",
    "    print(\"\\nCreating HUD overlay video...\")\n",
    "    create_hud_video(\n",
    "        str(input_video),\n",
    "        str(base_dir / \"video_processing\" / \"merged_timeline.json\"),\n",
    "        str(output_video)\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nInput video not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Verify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if output video was created\n",
    "if output_video.exists():\n",
    "    print(f\"✓ HUD overlay video created successfully!\")\n",
    "    print(f\"File size: {output_video.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    # Get video info\n",
    "    try:\n",
    "        cmd = [\"ffprobe\", \"-v\", \"quiet\", \"-show_entries\", \"format=duration,size\", \"-of\", \"default=noprint_wrappers=1\", str(output_video)]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(\"\\nVideo info:\")\n",
    "        print(result.stdout)\n",
    "    except:\n",
    "        print(\"Could not get video info (ffprobe not available)\")\n",
    "else:\n",
    "    print(\"❌ Output video not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze event distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count events by type\n",
    "event_counts = {}\n",
    "for event in timeline_data['timeline']:\n",
    "    event_type = event['event_type']\n",
    "    event_counts[event_type] = event_counts.get(event_type, 0) + 1\n",
    "\n",
    "# Plot event distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(event_counts.keys(), event_counts.values())\n",
    "plt.title('Event Distribution by Type')\n",
    "plt.xlabel('Event Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Timeline visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "colors = {\n",
    "    \"warning\": \"red\",\n",
    "    \"well_state\": \"lime\",\n",
    "    \"pipette_setting\": \"yellow\",\n",
    "    \"aspiration\": \"cyan\",\n",
    "    \"dispensing\": \"orange\", \n",
    "    \"tip_change\": \"white\"\n",
    "}\n",
    "\n",
    "y_pos = 0\n",
    "for event in timeline_data['timeline']:\n",
    "    start = event['start_time']\n",
    "    duration = event['end_time'] - event['start_time']\n",
    "    color = colors.get(event['event_type'], 'gray')\n",
    "    \n",
    "    plt.barh(y_pos, duration, left=start, color=color, alpha=0.7, \n",
    "             label=event['event_type'] if event['event_type'] not in [e.get_text() for e in plt.gca().get_legend_handles_labels()[1]])\n",
    "    plt.text(start + duration/2, y_pos, event['title'][:20], \n",
    "             ha='center', va='center', fontsize=8, rotation=0)\n",
    "    y_pos += 1\n",
    "\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Events')\n",
    "plt.title('Event Timeline')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}