{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class LabProtocolStep(BaseModel):\n",
    "    thinking: str = Field(\n",
    "        ...,\n",
    "        description=\"A brief explanation of the reasoning or intent behind this step; what is being accomplished or considered.\"\n",
    "    )\n",
    "    instruction: str = Field(\n",
    "        ...,\n",
    "        description=\"A clear, actionable instruction for what to do in this step; should be concise and unambiguous.\"\n",
    "    )\n",
    "    materials: list[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"A list of materials, reagents, or equipment required specifically for this step; leave empty if none.\"\n",
    "    )\n",
    "    notes: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Any additional context, tips, or warnings relevant to this step; optional.\"\n",
    "    )\n",
    "\n",
    "class LabProtocol(BaseModel):\n",
    "    thinking: str = Field(\n",
    "        ...,\n",
    "        description=\"A high-level summary of the overall reasoning, purpose, or approach of the protocol as a whole.\"\n",
    "    )\n",
    "    steps: list[LabProtocolStep] = Field(\n",
    "        ...,\n",
    "        description=\"An ordered list of LabProtocolStep objects representing each step in the protocol.\"\n",
    "    )\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENERATIVE_AI_API_KEY\"))\n",
    "\n",
    "video_file_name = \"output.mp4\"\n",
    "video_bytes = open(video_file_name, 'rb').read()\n",
    "\n",
    "content = types.Content(\n",
    "        parts=[\n",
    "            types.Part(\n",
    "                inline_data=types.Blob(data=video_bytes, mime_type='video/mp4')\n",
    "            ),\n",
    "            types.Part(text='break this down frame by frame and make a lab protocol for it')\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerError",
     "evalue": "500 INTERNAL. {'error': {'code': 500, 'message': 'An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting', 'status': 'INTERNAL'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gemini-2.5-pro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_mime_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_schema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLabProtocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/models.py:5821\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5819\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5820\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5821\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5822\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[1;32m   5823\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5824\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5825\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/models.py:4780\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4777\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4778\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4780\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4781\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4784\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;28;01melse\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mbody)\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:986\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    978\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    981\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    982\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m    983\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m    984\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m    985\u001b[0m   )\n\u001b[0;32m--> 986\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    988\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(\n\u001b[1;32m    989\u001b[0m       headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body\n\u001b[1;32m    990\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:879\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m(\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    876\u001b[0m     http_request: HttpRequest,\n\u001b[1;32m    877\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    878\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HttpResponse:\n\u001b[0;32m--> 879\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:869\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    863\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    864\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    868\u001b[0m   )\n\u001b[0;32m--> 869\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    871\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    872\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/work/random/hackathon/bio-memex/.venv/lib/python3.10/site-packages/google/genai/errors.py:106\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response_json, response)\n",
      "\u001b[0;31mServerError\u001b[0m: 500 INTERNAL. {'error': {'code': 500, 'message': 'An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting', 'status': 'INTERNAL'}}"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"models/gemini-2.5-pro\",\n",
    "    contents=content,\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": LabProtocol,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='{\\n  \"thinking\": \"The user wants a lab protocol for the concept of \\'breaking something down frame by frame\\'. I will interpret this as a procedure for analyzing a digital video file on a frame-by-frame basis, a common task in scientific research (e.g., motion analysis, microscopy, behavioral studies). The protocol will guide the user from software setup and defining parameters through the systematic analysis loop to data validation and archiving, ensuring a reproducible and rigorous workflow.\",\\n  \"steps\": [\\n    {\\n      \"thinking\": \"The first step is to prepare the necessary tools. This involves selecting and setting up the software and loading the media file that will be analyzed. This ensures the workspace is ready before the analysis begins.\",\\n      \"instruction\": \"Install or open a video analysis software and load the target video file.\",\\n      \"materials\": [\\n        \"Computer\",\\n        \"Video analysis software (e.g., ImageJ/FIJI, VLC, Kinovea)\",\\n        \"Digital video file for analysis\"\\n      ],\\n      \"notes\": \"Specialized software like ImageJ or Kinovea is recommended for quantitative measurements, while VLC is suitable for simple observational logging. Ensure the video file is stored locally for faster performance.\"\\n    },\\n    {\\n      \"thinking\": \"Before starting, it\\'s crucial to define what is being measured. This step formalizes the data collection process, ensuring consistency and focus. Creating a data sheet provides a structured way to record observations.\",\\n      \"instruction\": \"Create a spreadsheet or data sheet and define the specific parameters, events, or measurements to be recorded.\",\\n      \"materials\": [\\n        \"Spreadsheet software (e.g., Excel, Google Sheets)\",\\n        \"Lab notebook (digital or physical)\"\\n      ],\\n      \"notes\": \"Parameters could include: object position (x, y coordinates), presence/absence of an event, count of objects, or qualitative behavioral codes. Each column in your sheet should represent one parameter.\"\\n    },\\n    {\\n      \"thinking\": \"To save time, the user should first identify the relevant portion of the video. Analyzing an entire video frame by frame is often unnecessary. This step narrows the \\'region of interest\\' in time.\",\\n      \"instruction\": \"Play the video at normal speed to identify and note the start and end timestamps of the key section(s) for analysis.\",\\n      \"materials\": [],\\n      \"notes\": \"Record these timestamps in your data sheet. This helps focus the detailed analysis only on the relevant events.\"\\n    },\\n    {\\n      \"thinking\": \"This is the start of the core analysis loop. The process begins by navigating to the first frame of interest. This action sets the starting point for the systematic, frame-by-frame examination.\",\\n      \"instruction\": \"Navigate to the start timestamp identified in the previous step. Advance the video forward by a single frame.\",\\n      \"materials\": [],\\n      \"notes\": \"Familiarize yourself with the software\\'s hotkeys for single-frame forward/backward navigation (e.g., arrow keys or specific buttons). This will greatly increase efficiency.\"\\n    },\\n    {\\n      \"thinking\": \"With a single frame isolated, the next action is to perform the actual observation and data collection based on the predefined parameters. This is where the visual information is converted into structured data.\",\\n      \"instruction\": \"Carefully observe the current frame. Measure and record the data for each parameter defined in your data sheet.\",\\n      \"materials\": [\\n        \"Data sheet\"\\n      ],\\n      \"notes\": \"For each data entry, note the corresponding frame number or timestamp. Maintain consistency in your measurements (e.g., always measure to the center of an object).\"\\n    },\\n    {\\n      \"thinking\": \"The analysis is a repetitive process. This step instructs the user to continue the loop of advancing one frame and recording data until the entire region of interest has been covered. Repetition is key to a complete analysis.\",\\n      \"instruction\": \"Repeat the process of advancing one frame and recording data until the end timestamp of the relevant section is reached.\",\\n      \"materials\": [],\\n      \"notes\": \"Take short breaks to prevent eye strain and maintain focus, as this is a repetitive task that requires high attention to detail. Consistency is more important than speed.\"\\n    },\\n    {\\n      \"thinking\": \"Once data collection is complete, it\\'s essential to check for errors. This validation step ensures the quality and reliability of the collected data before it is used for further analysis.\",\\n      \"instruction\": \"Review the completed data sheet for outliers, typos, or missing values. Spot-check a few data points by navigating to the corresponding frames in the video to verify accuracy.\",\\n      \"materials\": [\\n        \"Completed data sheet\"\\n      ],\\n      \"notes\": \"If possible, have a colleague review a small subset of your analysis (e.g., 10% of the frames) to check for inter-rater reliability and reduce observer bias.\"\\n    },\\n    {\\n      \"thinking\": \"The final step is to secure the work for future use. Proper archiving ensures that the data, the source video, and the methods are preserved and can be easily retrieved and understood later.\",\\n      \"instruction\": \"Save the final data file with a clear, descriptive name. Archive the data file, the original video, and a copy of your parameter definitions together.\",\\n      \"materials\": [\\n        \"Data storage location (e.g., server, cloud storage, external drive)\"\\n      ],\\n      \"notes\": \"Use a standardized naming convention, such as \\'Project_VideoID_AnalysisDate.csv\\'. Back up your data to a secure, separate location.\"\\n    }\\n  ]\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.5-pro', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=1210, candidates_tokens_details=None, prompt_token_count=13, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=13)], thoughts_token_count=1431, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=2654, traffic_type=None), automatic_function_calling_history=[], parsed=LabProtocol(thinking=\"The user wants a lab protocol for the concept of 'breaking something down frame by frame'. I will interpret this as a procedure for analyzing a digital video file on a frame-by-frame basis, a common task in scientific research (e.g., motion analysis, microscopy, behavioral studies). The protocol will guide the user from software setup and defining parameters through the systematic analysis loop to data validation and archiving, ensuring a reproducible and rigorous workflow.\", steps=[LabProtocolStep(thinking='The first step is to prepare the necessary tools. This involves selecting and setting up the software and loading the media file that will be analyzed. This ensures the workspace is ready before the analysis begins.', instruction='Install or open a video analysis software and load the target video file.', materials=['Computer', 'Video analysis software (e.g., ImageJ/FIJI, VLC, Kinovea)', 'Digital video file for analysis'], notes='Specialized software like ImageJ or Kinovea is recommended for quantitative measurements, while VLC is suitable for simple observational logging. Ensure the video file is stored locally for faster performance.'), LabProtocolStep(thinking=\"Before starting, it's crucial to define what is being measured. This step formalizes the data collection process, ensuring consistency and focus. Creating a data sheet provides a structured way to record observations.\", instruction='Create a spreadsheet or data sheet and define the specific parameters, events, or measurements to be recorded.', materials=['Spreadsheet software (e.g., Excel, Google Sheets)', 'Lab notebook (digital or physical)'], notes='Parameters could include: object position (x, y coordinates), presence/absence of an event, count of objects, or qualitative behavioral codes. Each column in your sheet should represent one parameter.'), LabProtocolStep(thinking=\"To save time, the user should first identify the relevant portion of the video. Analyzing an entire video frame by frame is often unnecessary. This step narrows the 'region of interest' in time.\", instruction='Play the video at normal speed to identify and note the start and end timestamps of the key section(s) for analysis.', materials=[], notes='Record these timestamps in your data sheet. This helps focus the detailed analysis only on the relevant events.'), LabProtocolStep(thinking='This is the start of the core analysis loop. The process begins by navigating to the first frame of interest. This action sets the starting point for the systematic, frame-by-frame examination.', instruction='Navigate to the start timestamp identified in the previous step. Advance the video forward by a single frame.', materials=[], notes=\"Familiarize yourself with the software's hotkeys for single-frame forward/backward navigation (e.g., arrow keys or specific buttons). This will greatly increase efficiency.\"), LabProtocolStep(thinking='With a single frame isolated, the next action is to perform the actual observation and data collection based on the predefined parameters. This is where the visual information is converted into structured data.', instruction='Carefully observe the current frame. Measure and record the data for each parameter defined in your data sheet.', materials=['Data sheet'], notes='For each data entry, note the corresponding frame number or timestamp. Maintain consistency in your measurements (e.g., always measure to the center of an object).'), LabProtocolStep(thinking='The analysis is a repetitive process. This step instructs the user to continue the loop of advancing one frame and recording data until the entire region of interest has been covered. Repetition is key to a complete analysis.', instruction='Repeat the process of advancing one frame and recording data until the end timestamp of the relevant section is reached.', materials=[], notes='Take short breaks to prevent eye strain and maintain focus, as this is a repetitive task that requires high attention to detail. Consistency is more important than speed.'), LabProtocolStep(thinking=\"Once data collection is complete, it's essential to check for errors. This validation step ensures the quality and reliability of the collected data before it is used for further analysis.\", instruction='Review the completed data sheet for outliers, typos, or missing values. Spot-check a few data points by navigating to the corresponding frames in the video to verify accuracy.', materials=['Completed data sheet'], notes='If possible, have a colleague review a small subset of your analysis (e.g., 10% of the frames) to check for inter-rater reliability and reduce observer bias.'), LabProtocolStep(thinking='The final step is to secure the work for future use. Proper archiving ensures that the data, the source video, and the methods are preserved and can be easily retrieved and understood later.', instruction='Save the final data file with a clear, descriptive name. Archive the data file, the original video, and a copy of your parameter definitions together.', materials=['Data storage location (e.g., server, cloud storage, external drive)'], notes=\"Use a standardized naming convention, such as 'Project_VideoID_AnalysisDate.csv'. Back up your data to a secure, separate location.\")]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=18870 cached_content_token_count=None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      9\u001b[0m     client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mcount_tokens(\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.5-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m, contents\u001b[38;5;241m=\u001b[39mcontent\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ( e.g., total_tokens: 300 )\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39musage_metadata)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ( e.g., prompt_token_count: 301, candidates_token_count: 60, total_token_count: 361 )\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import time\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENERATIVE_AI_API_KEY\"))\n",
    "prompt = \"Tell me about this video\"\n",
    "your_file = client.files.upload(file=\"output.mov\")\n",
    "\n",
    "print(\n",
    "    client.models.count_tokens(\n",
    "        model=\"gemini-2.5-pro\", contents=content\n",
    "    )\n",
    ")\n",
    "# ( e.g., total_tokens: 300 )\n",
    "\n",
    "print(response.usage_metadata)\n",
    "# ( e.g., prompt_token_count: 301, candidates_token_count: 60, total_token_count: 361 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the response as a JSON string.\n",
    "print(response.text)\n",
    "\n",
    "# Use instantiated objects.\n",
    "my_videos: list[Video] = response.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=MY_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    ")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Summarize the video\"\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    stream_options={'include_usage': True},\n",
    "    extra_body={\n",
    "        'extra_body':\n",
    "        {\n",
    "            'google': {\n",
    "              'cached_content': \"cachedContents/0000aaaa1111bbbb2222cccc3333dddd4444eeee\"\n",
    "          }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk)\n",
    "    print(chunk.usage.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
