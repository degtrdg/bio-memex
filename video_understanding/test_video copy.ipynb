{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Video loaded from cache: files/p3d949zrnvip\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_GENERATIVE_AI_API_KEY\"))\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "video_json_path = \"myfile.json\"\n",
    "\n",
    "# If the file exists, load it; otherwise, upload and save\n",
    "if os.path.exists(video_json_path):\n",
    "    with open(video_json_path, \"r\") as f:\n",
    "        myfile_dict = json.load(f)\n",
    "    # Reconstruct a File object if needed, or just use the dict\n",
    "    myfile = types.File(**myfile_dict)\n",
    "    print(f\"Video loaded from cache: {myfile.name}\")\n",
    "else:\n",
    "    # myfile = client.files.upload(file=\"videos/output_long_again_2.mp4\")\n",
    "    myfile = client.files.upload(file=\"videos/output_long_again_2_timestamped.mp4\")\n",
    "    print(f\"Video uploaded: {myfile.name}\")\n",
    "    # Save the model dump to JSON\n",
    "    with open(video_json_path, \"w\") as f:\n",
    "        f.write(myfile.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 1: PROCEDURE EXTRACTION\n",
      "==================================================\n",
      "Token count: total_tokens=19668 cached_content_token_count=None\n",
      "PROCEDURE EXTRACTION COMPLETE\n",
      "Goal wells: 3\n",
      "Reagent sources: ['A', 'B', 'C']\n",
      "Timestamp range: 0:00 - 1:12\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: PROCEDURE EXTRACTION (runs first)\n",
    "from video_understanding.multi_prompts import create_procedure_extraction_prompt\n",
    "from video_understanding.simple_models import ProcedureExtraction\n",
    "\n",
    "procedure_json_path = \"procedure_result.json\"\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"STEP 1: PROCEDURE EXTRACTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "system_prompt, user_prompt = create_procedure_extraction_prompt()\n",
    "\n",
    "contents = [myfile, user_prompt]\n",
    "print(f\"Token count: {client.models.count_tokens(model='models/gemini-2.5-pro', contents=contents)}\")\n",
    "\n",
    "procedure_response = client.models.generate_content(\n",
    "    model=\"models/gemini-2.5-pro\",\n",
    "    contents=contents,\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": ProcedureExtraction,\n",
    "        \"system_instruction\": system_prompt\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "procedure_result = procedure_response.parsed\n",
    "with open(procedure_json_path, \"w\") as f:\n",
    "    f.write(procedure_result.model_dump_json())\n",
    "print(\"PROCEDURE EXTRACTION COMPLETE\")\n",
    "print(f\"Goal wells: {len(procedure_result.goal_wells)}\")\n",
    "print(f\"Reagent sources: {procedure_result.reagent_sources}\")\n",
    "print(f\"Timestamp range: {procedure_result.timestamp_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nfrom video_understanding.simple_models import ProcedureExtraction\n\nprocedure_json_path = \"procedure_result.json\"\n\n# Try to load it back in if it exists\nif os.path.exists(procedure_json_path):\n    with open(procedure_json_path, \"r\") as f:\n        loaded_json = f.read()\n    procedure_result = ProcedureExtraction.model_validate_json(loaded_json)\n    print(\"Loaded ProcedureExtraction from file:\")\n    print(f\"Goal wells: {len(procedure_result.goal_wells)}\")\n    print(f\"Reagent sources: {procedure_result.reagent_sources}\")\n    print(f\"Timestamp range: {procedure_result.timestamp_range}\")\nelse:\n    print(\"ProcedureExtraction file not found.\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# STEP 2: OBJECTIVE EVENTS EXTRACTION\nfrom video_understanding.multi_prompts import create_objective_events_prompt\nfrom video_understanding.simple_models import ObjectiveEventsList\nfrom pydantic import BaseModel, Field\nfrom typing import List, Union\n\n\nobjective_events_json_path = \"objective_events_result.json\"\n\nprint(\"=\" * 50)\nprint(\"STEP 2: OBJECTIVE EVENTS EXTRACTION\")\nprint(\"=\" * 50)\n\nsystem_prompt, user_prompt = create_objective_events_prompt(procedure_result)\n\ncontents = [myfile, user_prompt]\nprint(f\"Token count: {client.models.count_tokens(model='models/gemini-2.5-pro', contents=contents)}\")\n\n\n\nobjective_response = client.models.generate_content(\n    model=\"models/gemini-2.5-pro\",\n    contents=contents,\n    config={\n        \"response_mime_type\": \"application/json\",\n        \"response_schema\": ObjectiveEventsList,\n        \"system_instruction\": system_prompt\n    },\n)\n\nobjective_events_result = objective_response.parsed\nobjective_events = objective_events_result.events\n\nwith open(objective_events_json_path, \"w\") as f:\n    f.write(objective_events_result.model_dump_json())\n\nprint(f\"OBJECTIVE EVENTS EXTRACTION COMPLETE\")\nprint(f\"Total events found: {len(objective_events)}\")\n\n# Count by type\nevent_counts = {}\nfor event in objective_events:\n    event_type = type(event).__name__\n    event_counts[event_type] = event_counts.get(event_type, 0) + 1\n\nfor event_type, count in event_counts.items():\n    print(f\"- {event_type}: {count}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nfrom video_understanding.simple_models import ObjectiveEventsList\n\nobjective_events_json_path = \"objective_events_result.json\"\n\n# Try to load it back in if it exists\nif os.path.exists(objective_events_json_path):\n    with open(objective_events_json_path, \"r\") as f:\n        loaded_json = f.read()\n    objective_events_result = ObjectiveEventsList.model_validate_json(loaded_json)\n    print(\"Loaded ObjectiveEventsList from file:\")\n    print(f\"Total events found: {len(objective_events_result.events)}\")\n    event_counts = {}\n    for event in objective_events_result.events:\n        event_type = type(event).__name__\n        event_counts[event_type] = event_counts.get(event_type, 0) + 1\n    for event_type, count in event_counts.items():\n        print(f\"- {event_type}: {count}\")\nelse:\n    print(\"ObjectiveEventsList file not found.\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# STEP 3: ANALYSIS EVENTS EXTRACTION\nfrom video_understanding.multi_prompts import create_analysis_events_prompt\nfrom video_understanding.simple_models import AnalysisEventsResult\n\n\nprint(\"=\" * 50)\nprint(\"STEP 3: ANALYSIS EVENTS EXTRACTION\")\nprint(\"=\" * 50)\n\nsystem_prompt, user_prompt = create_analysis_events_prompt(procedure_result, objective_events_result)\n\ncontents = [myfile, user_prompt]\nprint(f\"Token count: {client.models.count_tokens(model='models/gemini-2.5-pro', contents=contents)}\")\n\n\nanalysis_response = client.models.generate_content(\n    model=\"models/gemini-2.5-pro\",\n    contents=contents,\n    config={\n        \"response_mime_type\": \"application/json\",\n        \"response_schema\": AnalysisEventsResult,\n        \"system_instruction\": system_prompt\n    },\n)\n\nanalysis_events = analysis_response.parsed\nprint(\"ANALYSIS EVENTS EXTRACTION COMPLETE\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis_events_result.json\", \"w\") as f:\n",
    "    f.write(analysis_response.parsed.model_dump_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}